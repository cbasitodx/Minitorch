{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minitorch import *\n",
    "from minitorch.nn import *\n",
    "from minitorch.optim import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use case: Creation of a Multi Layer Perceptron (MLP) that learns the AND Gate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we define our model. This one will consist of two linear layers. The first one is the input layer, and it feeds its output to a ReLU function for cleaning negative outputs. The second layer feeds its output to a Sigmoid function for predicting probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self):\n",
    "        self.layers = Sequential(\n",
    "            Linear(2,3, seed=1241241),\n",
    "            ReLU(),\n",
    "            Linear(3,1, seed=1241241),\n",
    "            Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input : Tensor):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a loss function. Since we are doing a binary classification task, we'll be using the **Binary Cross Entropy** loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = BinaryCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define an optimization algorithm. As for the version *v.1.0.0* of ***Minitorch***, only single-element batches are supported. Therefore, we'll be using **Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_sgd = SGD(model.parameters(), lr = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a training loop. In this loop we'll be iterating through all the training examples. We then obtain the output of the model for each example, compute the loss function and then compute its gradient. Once the gradient of the loss function is calculated, we use Stochastic Gradient Descent to perform the updates of the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = Tensor([[0,0], [0,1], [1,0], [1,1]])\n",
    "label = Tensor([0,0,0,1]) # AND function\n",
    "\n",
    "n_training_ex = len(data)\n",
    "\n",
    "epoch = 1000\n",
    "\n",
    "for i in range(epoch):\n",
    "    for idx in range(n_training_ex):\n",
    "\n",
    "        d = data[idx]\n",
    "        l = label[idx]\n",
    "\n",
    "        optim_sgd.zero_grad()\n",
    "\n",
    "        output = model.forward(d)\n",
    "\n",
    "        loss(output, l)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim_sgd.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we visualize our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output for (0,0):  1.8408679308744555e-08\n",
      "Model output for (0,1):  0.00018656888445709013\n",
      "Model output for (1,0):  0.00017551873734118786\n",
      "Model output for (1,1):  0.9975393850659847\n"
     ]
    }
   ],
   "source": [
    "print(\"Model output for (0,0): \", model.forward(data[0]).item().data)\n",
    "print(\"Model output for (0,1): \", model.forward(data[1]).item().data)\n",
    "print(\"Model output for (1,0): \", model.forward(data[2]).item().data)\n",
    "print(\"Model output for (1,1): \", model.forward(data[3]).item().data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
